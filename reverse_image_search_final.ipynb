{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "249deb01",
   "metadata": {},
   "source": [
    "# download directory from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a564abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "199902f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/u/1/uc?id=1Uo6-h0HViUVVp65TssLsYP8-79MllYdN --output CAI2.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "83ea9120",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvzf CAI2.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bcf02d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gdown https://drive.google.com/uc?id=137RyRjvTBkBiIfeYBNZBtViDHQ6_Ewsp --output caltech101.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7a25b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls caltech101.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2cc2625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tar -xvzf caltech101.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a049de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv CAI2 datasets/cai2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "fb25a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -rf datasets/caltech101/BACKGROUND_Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48268bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19079ba4",
   "metadata": {},
   "source": [
    "# import and model tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8433f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pickle\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4f91d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_picker(name):\n",
    "    if (name == 'vgg16'):\n",
    "        model = VGG16(weights='imagenet',\n",
    "                      include_top=False,\n",
    "                      input_shape=(224, 224, 3),\n",
    "                      pooling='max')\n",
    "    elif (name == 'vgg19'):\n",
    "        model = VGG19(weights='imagenet',\n",
    "                      include_top=False,\n",
    "                      input_shape=(224, 224, 3),\n",
    "                      pooling='max')\n",
    "    elif (name == 'mobilenet'):\n",
    "        model = MobileNet(weights='imagenet',\n",
    "                          include_top=False,\n",
    "                          input_shape=(224, 224, 3),\n",
    "                          pooling='max',\n",
    "                          depth_multiplier=1,\n",
    "                          alpha=1)\n",
    "    elif (name == 'inception'):\n",
    "        model = InceptionV3(weights='imagenet',\n",
    "                            include_top=False,\n",
    "                            input_shape=(224, 224, 3),\n",
    "                            pooling='max')\n",
    "    elif (name == 'resnet'):\n",
    "        model = ResNet50(weights='imagenet',\n",
    "                         include_top=False,\n",
    "                         input_shape=(224, 224, 3),\n",
    "                        pooling='max')\n",
    "    elif (name == 'xception'):\n",
    "        model = Xception(weights='imagenet',\n",
    "                         include_top=False,\n",
    "                         input_shape=(224, 224, 3),\n",
    "                         pooling='max')\n",
    "    else:\n",
    "        print(\"Specified model not available\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a8d324dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_architecture = 'resnet'\n",
    "model = model_picker(model_architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "498a6af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img_path, model):\n",
    "    input_shape = (224, 224, 3)\n",
    "    img = image.load_img(img_path,\n",
    "                         target_size=(input_shape[0], input_shape[1]))\n",
    "    img_array = image.img_to_array(img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = preprocess_input(expanded_img_array)\n",
    "    features = model.predict(preprocessed_img)\n",
    "    flattened_features = features.flatten()\n",
    "    normalized_features = flattened_features / norm(flattened_features)\n",
    "    return normalized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "35b1191c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "#features = extract_features('datasets/caltech101/laptop/image_0033.jpg', model)\n",
    "#print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "76df5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "extensions = ['.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG']\n",
    "\n",
    "def get_file_list(root_dir):\n",
    "    file_list = []\n",
    "    for root, directories, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if any(ext in filename for ext in extensions):\n",
    "                file_list.append(os.path.join(root, filename))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "24a0e35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1833 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "datagen = tensorflow.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "generator = datagen.flow_from_directory(root_dir,\n",
    "                                        target_size=(224, 224),\n",
    "                                        class_mode=None,\n",
    "                                        shuffle=False)\n",
    "\n",
    "num_images = len(generator.filenames)\n",
    "num_epochs = int(math.ceil(num_images / batch_size))\n",
    "\n",
    "start_time = time.time()\n",
    "feature_list = []\n",
    "feature_list = model.predict_generator(generator, num_epochs)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cceb68ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num images   =  1833\n",
      "Shape of feature_list =  (480, 2048)\n",
      "Time taken in sec =  165.81499981880188\n"
     ]
    }
   ],
   "source": [
    "for i, features in enumerate(feature_list):\n",
    "    feature_list[i] = features / norm(features)\n",
    "\n",
    "feature_list = feature_list.reshape(len(feature_list), -1)\n",
    "\n",
    "print(\"Num images   = \", len(generator.classes))\n",
    "print(\"Shape of feature_list = \", feature_list.shape)\n",
    "print(\"Time taken in sec = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ab0bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'datasets/cai2'\n",
    "filenames = sorted(get_file_list(root_dir))\n",
    "\n",
    "feature_list = []\n",
    "for i in tqdm_notebook(range(len(filenames))):\n",
    "    try:\n",
    "        feature_list.append(extract_features(filenames[i], model))\n",
    "    except Exception as e:\n",
    "        print(f\"Error{e} occurs when processing file {filenames[i]}\") \n",
    "import pickle\n",
    "pickle.dump(feature_list, open('pickle/features-cai101-resnet.pickle', 'wb'))\n",
    "pickle.dump(filenames, open('pickle/filenames-cai101.pickle','wb'))\n",
    "pickle.dump(feature_list, open('pickle/features-cai101-' + model_architecture + '.pickle', 'wb'))\n",
    "pickle.dump(generator.classes, open('pickle/class_ids-cai101.pickle',  'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e3fffb",
   "metadata": {},
   "source": [
    "# model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "17050d1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAINMODELBUILDING \n",
    "#IMPORTANT : RUN TO GET COMPLETED MODEL BEFORE USING THE PICKLE\n",
    "#insert labels\n",
    "training_img_labels = [\"เครื่องจำหน่ายเครื่องดื่มเย็น\", \n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"EDC\", \n",
    "                        \"EDC\",\n",
    "                        \"EDC\",\n",
    "                        \"EDC\",\n",
    "                        \"EDC\",\n",
    "                        \"EDC\",\n",
    "                        \"EDC\",\n",
    "                        \"EDC\",\n",
    "                        \"EDC\",\n",
    "                        \"EDC\",\n",
    "                        \"EDC\",\n",
    "                        \"EDC\",\n",
    "                        \"EDC\",\n",
    "                        \"EDC\",\n",
    "                        \"EDC\",\n",
    "                        \"EDC\",\n",
    "                        \"EDC\",\n",
    "                        \"EDC\", \n",
    "                       \"EDC\",\n",
    "                        \"EDC\",\n",
    "                        \"EDC\", \n",
    "                       \"EDC\",\n",
    "                        \"EDC\",\n",
    "                       \"เครื่องผลิตน้ำแข็ง\", \n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",]\n",
    "\n",
    "#link file directory (hard code)\n",
    "filenames = [\"datasets/cai2/cold drink freezer/20211124_114324(0).jpg\",\n",
    "            \"datasets/cai2/cold drink freezer/20211124_114324(0).jpg\",\n",
    "             \"datasets/cai2/cold drink freezer/20211124_114326(0).jpg\",\n",
    "             \"datasets/cai2/cold drink freezer/20211124_114327(0).jpg\",\n",
    "             \"datasets/cai2/cold drink freezer/20211124_114328.jpg\",\n",
    "            \"datasets/cai2/cold drink freezer/20211124_114330(0).jpg\",\n",
    "            \"datasets/cai2/cold drink freezer/20211124_114331.jpg\",\n",
    "            \"datasets/cai2/cold drink freezer/20211124_114332.jpg\",\n",
    "            \"datasets/cai2/cold drink freezer/20211124_114334.jpg\",\n",
    "            \"datasets/cai2/cold drink freezer/20211124_114335.jpg\",\n",
    "            \"datasets/cai2/cold drink freezer/20211124_114336.jpg\",\n",
    "            \"datasets/cai2/cold drink freezer/20211124_114338.jpg\",\n",
    "            \"datasets/cai2/cold drink freezer/20211124_114340(0).jpg\",\n",
    "            \"datasets/cai2/cold drink freezer/20211124_114341(0).jpg\",\n",
    "            \"datasets/cai2/cold drink freezer/20211124_114342.jpg\",\n",
    "            \"datasets/cai2/cold drink freezer/20211124_114345(0).jpg\",\n",
    "            \"datasets/cai2/cold drink freezer/20211124_114347(0).jpg\",\n",
    "            \"datasets/cai2/EDC/20211210_123243_001 - Copy.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_004.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_007.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_011.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_012.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_013.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_014.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_015.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_016.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_017.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_018.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_019.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_020.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_030.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_024.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_025.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_023.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_022.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_027.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_021.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_003.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_002.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123243_009.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_122731_Burst01.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_122740_Burst01.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_122823_Burst07.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_122823_Burst12.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_122823_Burst15.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_122823_Burst17.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_122823_Burst19.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_122936_Burst02.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_122936_Burst05.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_122936_Burst08.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_122936_Burst08.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_123026_Burst02.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_123026_Burst03.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_123026_Burst06.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_123026_Burst09.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_123026_Burst10.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_123026_Burst13.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_123026_Burst15.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_123026_Burst17.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_123026_Burst18.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_123026_Burst19.jpg\",\n",
    "            ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_list = []\n",
    "for i in tqdm_notebook(range(len(filenames))):\n",
    "    try:\n",
    "        feature_list.append(extract_features(filenames[i], model))\n",
    "    except Exception as e:\n",
    "        print(f\"Error{e} occurs when processing file {filenames[i]}\") \n",
    "\n",
    "import pickle\n",
    "pickle.dump(feature_list, open('pickle/features-cai50-resnet.pickle', 'wb'))\n",
    "pickle.dump(filenames, open('pickle/filenames-cai50.pickle','wb'))\n",
    "pickle.dump(feature_list, open('pickle/features-cai50-' + model_architecture + '.pickle', 'wb'))\n",
    "pickle.dump(generator.classes, open('pickle/class_ids-cai50.pickle',  'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c3ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAINMODELBUILDING 2\n",
    "#IMPORTANT : RUN TO GET COMPLETED MODEL BEFORE USING THE PICKLE\n",
    "#insert labels\n",
    "training_img_labels = [\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                      \"เครื่องจำหน่ายเครื่องดื่มเย็น\",\n",
    "                       \"EDC\",\n",
    "                        \"EDC\",\n",
    "                        \"EDC\", \n",
    "                       \"EDC\",\n",
    "                        \"EDC\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"เครื่องผลิตน้ำแข็ง\",\n",
    "                      \"scaner\",\n",
    "                      \"scaner\",\n",
    "                      \"scaner\",\n",
    "                      \"scaner\",\n",
    "                      ]\n",
    "\n",
    "#link file directory (hard code)\n",
    "filenames = [\"datasets/cai2/cold drink freezer/20211124_114331.jpg\",\n",
    "            \"datasets/cai2/cold drink freezer/20211124_114337(0).jpg\",\n",
    "             \"datasets/cai2/cold drink freezer/20211124_114405.jpg\",\n",
    "             \"datasets/cai2/cold drink freezer/20211124_114324.jpg\",\n",
    "             \"datasets/cai2/cold drink freezer/20211124_114352.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123313_011.jpg\",\n",
    "            \"datasets/cai2/EDC/IMG_25641210_123336_Burst07.jpg\",\n",
    "             \"datasets/cai2/EDC/IMG_25641210_123316_Burst20.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123325_028.jpg\",\n",
    "             \"datasets/cai2/EDC/20211210_123300_008.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_122731_Burst08.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_122807_Burst12.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_123026_Burst05.jpg\",\n",
    "             \"datasets/cai2/ice maker/IMG_25641210_122823_Burst12.jpg\",\n",
    "             \"datasets/cai2/Scanner/20211210_123615_014.jpg\",\n",
    "             \"datasets/cai2/Scanner/20211210_123625_029.jpg\",\n",
    "             \"datasets/cai2/Scanner/20211210_123615_025.jpg\",\n",
    "             \"datasets/cai2/Scanner/20211210_123555_020.jpg\",\n",
    "             'datasets/user_photo/DTRbn5VU8AAvmRg.jpg'\n",
    "            ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_list = []\n",
    "for i in tqdm_notebook(range(len(filenames))):\n",
    "    try:\n",
    "        feature_list.append(extract_features(filenames[i], model))\n",
    "    except Exception as e:\n",
    "        print(f\"Error{e} occurs when processing file {filenames[i]}\") \n",
    "\n",
    "import pickle\n",
    "pickle.dump(feature_list, open('pickle/features-cai4-resnet.pickle', 'wb'))\n",
    "pickle.dump(filenames, open('pickle/filenames-cai4.pickle','wb'))\n",
    "pickle.dump(feature_list, open('pickle/features-cai4-' + model_architecture + '.pickle', 'wb'))\n",
    "pickle.dump(generator.classes, open('pickle/class_ids-cai4.pickle',  'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21320bf0",
   "metadata": {},
   "source": [
    "# nearest neighbor of taken picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a8fbdd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible labels are ['EDC', 'เครื่องจำหน่ายเครื่องดื่มเย็น']\n"
     ]
    }
   ],
   "source": [
    "#RUN THIS AFTER GETTING THE MODEL RENDERED AND PICKLED\n",
    "#this is main module\n",
    "import pickle\n",
    "from collections import Counter\n",
    "filenames = pickle.load(open('pickle/filenames-cai4.pickle', 'rb'))\n",
    "feature_list = pickle.load(open('pickle/features-cai4-resnet.pickle','rb'))\n",
    "class_ids = pickle.load(open('pickle/class_ids-cai4.pickle', 'rb'))\n",
    "                      \n",
    "#nearest neighbors fitting  \n",
    "quary_image = 'datasets/user_photo/EiJ5zZ7VgAAfLee.jpg'\n",
    "import tensorflow\n",
    "neighbors = NearestNeighbors(n_neighbors=5, algorithm='brute', metric='euclidean').fit(feature_list)\n",
    "#add picture directory here                                                \n",
    "query_image_feature = extract_features(quary_image ,model)\n",
    "distances, indices = neighbors.kneighbors([query_image_feature])\n",
    "\n",
    "similar_img_labels = [training_img_labels[similar_index] for similar_index in indices[0]]\n",
    "label_counter = Counter(similar_img_labels)\n",
    "most_common_labels =  label_counter.most_common(2)\n",
    "most_common_label_str = [label for label, freq in most_common_labels]\n",
    "\n",
    "print(f\"Possible labels are {most_common_label_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b307d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filenames = pickle.load(open('pickle/filenames-cai100.pickle', 'rb'))\n",
    "feature_list = pickle.load(open('pickle/features-cai100-resnet.pickle','rb'))\n",
    "class_ids = pickle.load(open('pickle/class_ids-cai100.pickle', 'rb'))\n",
    "                      \n",
    "#nearest neighbors fitting             \n",
    "import tensorflow\n",
    "neighbors = NearestNeighbors(n_neighbors=5, algorithm='brute', metric='euclidean').fit(feature_list)\n",
    "#add picture directory here                                                \n",
    "query_image_feature = extract_features('datasets/user_photo/DTRbn5VU8AAvmRg.jpg' ,model)\n",
    "distances, indices = neighbors.kneighbors([query_image_feature])\n",
    "\n",
    "similar_img_labels = [training_img_labels[similar_index] for similar_index in indices[0]]\n",
    "label_counter = Counter(similar_img_labels)\n",
    "most_common_labels =  label_counter.most_common(5)\n",
    "most_common_label_str = [label for label, freq in most_common_labels]\n",
    "\n",
    "print(f\"Possible labels are {most_common_label_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c8980",
   "metadata": {},
   "source": [
    "# ploting graph / feature inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b6479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filenames = pickle.load(open('pickle/filenames-cai4.pickle', 'rb'))\n",
    "feature_list = pickle.load(open('pickle/features-cai4-resnet.pickle','rb'))\n",
    "class_ids = pickle.load(open('pickle/class_ids-cai4.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3eeb1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import random\n",
    "import time\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b72c1a8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#filenames = pickle.load(open('dump/filenames-cai.pickle', 'rb'))\n",
    "#feature_list = pickle.load(open('dump/features-cai-resnet.pickle', 'rb'))\n",
    "#class_ids = pickle.load(open('dump/class_ids-cai.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9ed72a30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images =  18\n",
      "Number of features per image =  2048\n"
     ]
    }
   ],
   "source": [
    "num_images = len(filenames)\n",
    "num_features_per_image = len(feature_list[0])\n",
    "print(\"Number of images = \", num_images)\n",
    "print(\"Number of features per image = \", num_features_per_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ec689aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = NearestNeighbors(n_neighbors=5,\n",
    "                             algorithm='brute',\n",
    "                             metric='euclidean').fit(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063c33ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image_indices = [18]\n",
    "\n",
    "for image_index in target_image_indices:\n",
    "    distances, indices = neighbors.kneighbors([feature_list[image_index]])\n",
    "    plt.imshow(mpimg.imread(filenames[random_index]), interpolation='lanczos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mpimg.imread(filenames[indices[0][1]]), interpolation='lanczos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5156b6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.7183277\n",
      "0.7189592\n",
      "0.73276174\n",
      "0.74223596\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(distances[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "621acf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get the classname\n",
    "def classname(str):\n",
    "    return str.split('/')[-2]\n",
    "\n",
    "\n",
    "# Helper function to get the classname and filename\n",
    "def classname_filename(str):\n",
    "    return str.split('/')[-2] + '/' + str.split('/')[-1]\n",
    "\n",
    "\n",
    "# Helper functions to plot the nearest images given a query image\n",
    "def plot_images(filenames, distances):\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        images.append(mpimg.imread(filename))\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    columns = 4\n",
    "    for i, image in enumerate(images):\n",
    "        ax = plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "        if i == 0:\n",
    "            ax.set_title(\"Query Image\\n\" + classname_filename(filenames[i]))\n",
    "        else:\n",
    "            ax.set_title(\"Similar Image\\n\" + classname_filename(filenames[i]) +\n",
    "                         \"\\nDistance: \" +\n",
    "                         str(float(\"{0:.2f}\".format(distances[i]))))\n",
    "        plt.imshow(image)\n",
    "        # To save the plot in a high definition format i.e. PDF, uncomment the following line:\n",
    "        #plt.savefig('results/' + str(random.randint(0,10000))+'.pdf', format='pdf', dpi=1000)\n",
    "        # We will use this line repeatedly in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7294d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    random_image_index = random.randint(0, num_images )\n",
    "    distances, indices = neighbors.kneighbors([feature_list[random_image_index]])\n",
    "    # Don't take the first closest image as it will be the same image\n",
    "    similar_image_paths = [filenames[random_image_index]] + \\\n",
    "        [filenames[indices[0][i]] for i in range(1, 4)]\n",
    "    plot_images(similar_image_paths, distances[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4540f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image_indices = [18]\n",
    "\n",
    "for image_index in target_image_indices:\n",
    "    distances, indices = neighbors.kneighbors([feature_list[image_index]])\n",
    "    # Don't take the first closest image as it will be the same image\n",
    "    similar_image_paths = [filenames[image_index]] + \\\n",
    "        [filenames[indices[0][i]] for i in range(1, 4)]\n",
    "    plot_images(similar_image_paths, distances[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db15a250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median distance between all photos:  0.82266486\n",
      "Max distance between all photos:  1.1236137\n",
      "Median distance among most similar photos:  0.25919443\n"
     ]
    }
   ],
   "source": [
    "neighbors = NearestNeighbors(n_neighbors=len(feature_list),\n",
    "                             algorithm='brute',\n",
    "                             metric='euclidean').fit(feature_list)\n",
    "distances, indices = neighbors.kneighbors(feature_list)\n",
    "\n",
    "# Calculating some stats\n",
    "print(\"Median distance between all photos: \", np.median(distances))\n",
    "print(\"Max distance between all photos: \", np.max(distances))\n",
    "print(\"Median distance among most similar photos: \",\n",
    "      np.median(distances[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5157c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = feature_list[:]\n",
    "selected_filenames = filenames[:]\n",
    "selected_class_ids = class_ids[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e57937a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 1832 samples in 0.003s...\n",
      "[t-SNE] Computed neighbors for 1832 samples in 0.258s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1832\n",
      "[t-SNE] Computed conditional probabilities for sample 1832 / 1832\n",
      "[t-SNE] Mean sigma: 0.261925\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 52.806129\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.200920\n",
      "t-SNE done! Time elapsed: 7.640759706497192 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# You can play with these values and see how the results change\n",
    "n_components = 2\n",
    "verbose = 1\n",
    "perplexity = 40\n",
    "n_iter = 1000\n",
    "metric = 'euclidean'\n",
    "\n",
    "time_start = time.time()\n",
    "tsne_results = TSNE(n_components=n_components,\n",
    "                    verbose=verbose,\n",
    "                    perplexity=perplexity,\n",
    "                    n_iter=n_iter,\n",
    "                    metric=metric).fit_transform(selected_features)\n",
    "\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time() - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb16d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#still not debugged\n",
    "color_map = plt.cm.get_cmap('coolwarm')\n",
    "scatter_plot = plt.scatter(tsne_results[:, 0],\n",
    "                           tsne_results[:, 1],\n",
    "                           c=12,\n",
    "                           cmap=color_map)\n",
    "plt.colorbar(scatter_plot)\n",
    "plt.show()\n",
    "# To save the plot in a high definition format i.e. PDF, uncomment the following line:\n",
    "#plt.savefig('results/' + str(ADD_NAME_HERE)+'.pdf', format='pdf', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f58ee649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from matplotlib.cbook import get_sample_data\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def plot_images_in_2d(x, y, image_paths, axis=None, zoom=1):\n",
    "    if axis is None:\n",
    "        axis = plt.gca()\n",
    "    x, y = np.atleast_1d(x, y)\n",
    "    for x0, y0, image_path in zip(x, y, image_paths):\n",
    "        image = Image.open(image_path)\n",
    "        image.thumbnail((100, 100), Image.ANTIALIAS)\n",
    "        img = OffsetImage(image, zoom=zoom)\n",
    "        anno_box = AnnotationBbox(img, (x0, y0),\n",
    "                                  xycoords='data',\n",
    "                                  frameon=False)\n",
    "        axis.add_artist(anno_box)\n",
    "    axis.update_datalim(np.column_stack([x, y]))\n",
    "    axis.autoscale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4dd9877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tsne(x, y, selected_filenames):\n",
    "    fig, axis = plt.subplots()\n",
    "    fig.set_size_inches(22, 22, forward=True)\n",
    "    plot_images_in_2d(x, y, selected_filenames, zoom=0.3, axis=axis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c8d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    show_tsne(tsne_results[:, 0], tsne_results[:, 1], selected_filenames)\n",
    "except Exception as e:\n",
    "        print(f\"Error{e} occurs when processing file {filenames[i]}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "afef63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_to_grid_plotter_manual(x, y, selected_filenames):\n",
    "    S = 2000\n",
    "    s = 100\n",
    "    x = (x - min(x)) / (max(x) - min(x))\n",
    "    y = (y - min(y)) / (max(y) - min(y))\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    filename_plot = []\n",
    "    x_y_dict = {}\n",
    "    for i, image_path in enumerate(selected_filenames):\n",
    "        a = np.ceil(x[i] * (S - s))\n",
    "        b = np.ceil(y[i] * (S - s))\n",
    "        a = int(a - np.mod(a, s))\n",
    "        b = int(b - np.mod(b, s))\n",
    "        if str(a) + \"|\" + str(b) in x_y_dict:\n",
    "            continue\n",
    "        x_y_dict[str(a) + \"|\" + str(b)] = 1\n",
    "        x_values.append(a)\n",
    "        y_values.append(b)\n",
    "        filename_plot.append(image_path)\n",
    "    fig, axis = plt.subplots()\n",
    "    fig.set_size_inches(22, 22, forward=True)\n",
    "    plot_images_in_2d(x_values, y_values, filename_plot, zoom=.58, axis=axis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f5778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_to_grid_plotter_manual(tsne_results[:, 0], tsne_results[:, 1],\n",
    "                            selected_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "eed14fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature_dimensions = 60\n",
    "pca = PCA(n_components=num_feature_dimensions)\n",
    "pca.fit(feature_list)\n",
    "feature_list_compressed = pca.transform(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "a0fd1c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = NearestNeighbors(n_neighbors=5,\n",
    "                             algorithm='brute',\n",
    "                             metric='euclidean').fit(feature_list_compressed)\n",
    "distances, indices = neighbors.kneighbors([feature_list_compressed[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f37d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    random_image_index = random.randint(0,60)\n",
    "    distances, indices = neighbors.kneighbors(\n",
    "        [feature_list_compressed[random_image_index]])\n",
    "    # Don't take the first closest image as it will be the same image\n",
    "    similar_image_paths = [filenames[random_image_index]] + \\\n",
    "        [filenames[indices[0][i]] for i in range(1, 4)]\n",
    "    plot_images(similar_image_paths, distances[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "cd9bea60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 60 nearest neighbors...\n",
      "[t-SNE] Indexed 61 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 61 samples in 0.007s...\n",
      "[t-SNE] Computed conditional probabilities for sample 61 / 61\n",
      "[t-SNE] Mean sigma: 0.387334\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 49.974503\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.267522\n",
      "t-SNE done! Time elapsed: 0.3359649181365967 seconds\n"
     ]
    }
   ],
   "source": [
    "selected_features = feature_list_compressed[:4000]\n",
    "selected_class_ids = class_ids[:4000]\n",
    "selected_filenames = filenames[:4000]\n",
    "\n",
    "time_start = time.time()\n",
    "tsne_results = TSNE(n_components=2, verbose=1,\n",
    "                    metric='euclidean').fit_transform(selected_features)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time() - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f6f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#still not debugged\n",
    "color_map = plt.cm.get_cmap('coolwarm')\n",
    "scatter_plot = plt.scatter(tsne_results[:, 0],\n",
    "                           tsne_results[:, 1],\n",
    "                           c=selected_class_ids,\n",
    "                           cmap=color_map)\n",
    "plt.colorbar(scatter_plot)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
